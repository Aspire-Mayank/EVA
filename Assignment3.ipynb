{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayank01/EVA/blob/master/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ip4fw914FZX",
        "colab_type": "text"
      },
      "source": [
        "###Importing Keras library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5PUzrYcqxIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqzNu2ZD4IIb",
        "colab_type": "text"
      },
      "source": [
        "###Importing main weapons of Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz6307zO4MCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47cAXtC34Nn7",
        "colab_type": "text"
      },
      "source": [
        "###Loading the MNIST DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCPdft3v4SoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEsJhpwK4UHJ",
        "colab_type": "text"
      },
      "source": [
        "###Analysing DataSet/Visualizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zjs3IIP4XbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "c3f56ba4-b408-4a1e-b78e-2244f1f23aaf"
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[2])"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb5c0465eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN9RXoJ05NNo",
        "colab_type": "text"
      },
      "source": [
        "### Re-arranging of training and test data of input image 28*28"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJvD8rg15Nsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awaYvIHT5Zdo",
        "colab_type": "text"
      },
      "source": [
        "###1. Normalizing the data\n",
        "###2. casting of test, training data to float\n",
        "###3. diving cast data to 255 bytes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taXZPZ8a5Z0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufpwhpo25ee8",
        "colab_type": "text"
      },
      "source": [
        "### printing Training Data from 0-10 indexs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cikZ7EEU5e2H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f2884361-fb60-4ce9-bf32-e8419b0f3327"
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2drxuLVb5j9j",
        "colab_type": "text"
      },
      "source": [
        "### convert 1-Dimensional class array to 10-Dimensional matrix using keras np_utils."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp-ZFBmF5kUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mx30q-A5q2H",
        "colab_type": "text"
      },
      "source": [
        "### After matrix conversion we gets below array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN5Y_uC65rH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "e85e3a18-1ea5-47be-c89a-e0f0eba0da32"
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDKn9cJ45vl3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S19YO8KR5v_I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "9adad2cf-1811-4452-c6d4-7adc5c815f98"
      },
      "source": [
        "# loading packages for convolution layers\n",
        "from keras.layers import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32,3,3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(32,3,3, activation='relu'))\n",
        "#model.add(Convolution2D(32,3,3, activation='relu'))\n",
        "         \n",
        "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Convolution2D(10,1,1,activation='relu'))\n",
        "\n",
        "model.add(Convolution2D(10, 3,3, activation='relu'))          \n",
        "model.add(BatchNormalization())         \n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Convolution2D(10,3,3,activation='relu'))\n",
        "model.add(Convolution2D(10,3,3,activation='relu'))\n",
        "model.add(Convolution2D(10,3,3,activation='relu'))\n",
        "model.add(Convolution2D(10,3,3,activation='relu'))\n",
        "\n",
        "model.add(Convolution2D(10,1,1, activation='relu'))          \n",
        "model.add(Convolution2D(10, 3,3)) \n",
        "\n",
        "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "     \n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_OWXPz551mf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "outputId": "a7c6a72c-9bfb-4766-e543-e3893eb2e0c6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_170 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_171 (Conv2D)          (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_172 (Conv2D)          (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "conv2d_173 (Conv2D)          (None, 22, 22, 10)        910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 22, 22, 10)        40        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_174 (Conv2D)          (None, 9, 9, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_175 (Conv2D)          (None, 7, 7, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_176 (Conv2D)          (None, 5, 5, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_177 (Conv2D)          (None, 3, 3, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_178 (Conv2D)          (None, 3, 3, 10)          110       \n",
            "_________________________________________________________________\n",
            "conv2d_179 (Conv2D)          (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,636\n",
            "Trainable params: 15,552\n",
            "Non-trainable params: 84\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eykLj-ye56SK",
        "colab_type": "text"
      },
      "source": [
        "### Loss Function, Optimizer\n",
        ">1. Loss Function to calculate deflection/Difference btw actual value and predicted value\n",
        ">2. For Accurate prediction we need to minimize error which is work of backpropogation\n",
        ">3. the proccess to minimize error using updating weights and bias by function called \"optimizer\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iAn54DL56mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv6WyXql57tU",
        "colab_type": "text"
      },
      "source": [
        "###To fit model btw X_train and predicted y_train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6WfWuwt58DY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "1b1dd84c-4e0c-4c62-e9ff-140f424fd318"
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 21s 343us/step - loss: 0.2567 - acc: 0.9161\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 17s 291us/step - loss: 0.0808 - acc: 0.9759\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 17s 289us/step - loss: 0.0664 - acc: 0.9803\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 17s 290us/step - loss: 0.0581 - acc: 0.9818\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 18s 300us/step - loss: 0.0499 - acc: 0.9847\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 18s 304us/step - loss: 0.0454 - acc: 0.9859\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 19s 310us/step - loss: 0.0425 - acc: 0.9870\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 17s 291us/step - loss: 0.0409 - acc: 0.9874\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 17s 289us/step - loss: 0.0375 - acc: 0.9884\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 18s 304us/step - loss: 0.0349 - acc: 0.9891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb5c1df9588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmSdrCsSNCAc",
        "colab_type": "text"
      },
      "source": [
        "### Model to evaluate the score on the basis of actual output and predicted output. \n",
        "### it will evaluate loss and Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XAz8iGI6Eih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV1QdPIz6G9B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2afea159-674d-4bb6-9a5e-45c9a2cf9e1d"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.06837292695915094, 0.982]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcAUavunNJKk",
        "colab_type": "text"
      },
      "source": [
        "### Model predicting Y_pred from X_test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwqyNTXy6G-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiGMk2hl6MB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "0d906d68-1fe0-4b75-b774-78bb8ce8bd83"
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.2824080e-18 1.8373594e-08 1.0351942e-09 3.3420267e-11 2.6069375e-14\n",
            "  1.4778245e-16 7.4771802e-23 1.0000000e+00 1.4995008e-15 5.8789866e-09]\n",
            " [4.1128213e-05 7.7595033e-02 9.1819835e-01 6.0082189e-06 5.9184728e-08\n",
            "  7.5835311e-07 3.7059153e-03 3.1955519e-06 4.4939964e-04 1.5726670e-11]\n",
            " [2.2192213e-16 9.9999964e-01 3.4083830e-11 2.7571805e-09 1.1382550e-07\n",
            "  1.3336332e-10 7.7683411e-14 2.5272470e-07 8.2922746e-10 8.7943303e-13]\n",
            " [9.9973112e-01 1.8127698e-08 2.9315988e-08 3.1519143e-08 4.5549829e-08\n",
            "  5.1424431e-06 2.3539220e-04 4.5896202e-09 3.9429001e-06 2.4179928e-05]\n",
            " [4.4148682e-12 4.0686494e-08 4.0836719e-07 4.4137249e-11 9.9999869e-01\n",
            "  7.4676886e-13 1.6125225e-10 2.2804835e-07 1.3172382e-09 6.0521290e-07]\n",
            " [2.4523061e-17 1.0000000e+00 1.3457236e-12 3.5034430e-11 1.1259652e-08\n",
            "  5.7949019e-12 2.4809883e-15 4.9894120e-09 1.8876357e-10 1.2434133e-13]\n",
            " [1.2579914e-14 1.1069615e-03 2.0853302e-05 3.2232530e-09 9.9859029e-01\n",
            "  2.9785707e-10 6.4216205e-13 2.7831068e-04 3.2832029e-06 3.0217379e-07]\n",
            " [6.7798976e-07 5.4963649e-04 8.4754713e-05 1.1277550e-04 3.2937082e-03\n",
            "  1.7098446e-05 1.5284721e-05 9.1790652e-04 4.0624358e-04 9.9460196e-01]\n",
            " [4.6207131e-09 3.2877051e-10 1.5002208e-12 5.1806237e-12 2.1644730e-18\n",
            "  9.9999976e-01 8.2576079e-08 3.6843484e-12 4.4389122e-08 1.8074147e-08]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcL55PAH6Osa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN8VTN476X88",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-3Mp1rP6YQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "87b9f8bf-7999-4004-fdc8-9eaec44c19b3"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_14'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-19229f66b51a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filter %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mplot_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mvis_img_in_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-118-19229f66b51a>\u001b[0m in \u001b[0;36mvis_img_in_filter\u001b[0;34m(img, layer_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n\u001b[1;32m     23\u001b[0m                       layer_name = 'conv2d_14'):\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mimg_ascs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilter_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'conv2d_14'"
          ]
        }
      ]
    }
  ]
}