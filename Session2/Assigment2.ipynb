{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assigment2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayank01/EVA/blob/master/Session2/Assigment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gmb3rIlILfyy",
        "colab_type": "text"
      },
      "source": [
        "##Assigment 2:   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIxpn_khHfmq",
        "colab_type": "code",
        "outputId": "272f2150-c79a-47ad-a363-c9cd2b43295c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# https://keras.io/\n",
        "# install keras Framework using pip\n",
        "# importing or loading keras library\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRit7dl-H1uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading packages which required to do math array calculation: Numpy,\n",
        "# keras sequential models, layers which will use in CNN model, dataset to get learn for model \n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Convolution2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWK0ur_LIuds",
        "colab_type": "code",
        "outputId": "87dce89a-0d80-4a12-8278-5093b97530cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# mnist data set loading and divided into training and test data.\n",
        "(X_train, y_train),(X_test,y_test)= mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl9aCqRUJG1R",
        "colab_type": "code",
        "outputId": "90dceeb9-e47b-4827-d4d8-6292108b2c0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# printing input training data shape/matrix.\n",
        "print(X_train.shape)\n",
        "# loading matplot library for visulization \n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "# plotting of Input training data value of 0th index \n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6d1f49fdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI8lETjzJ-vA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rearranging of training and test data of input image 28*28\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IeR3FrJK8cJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizing the data\n",
        "# casting of test, training data to float\n",
        "# diving cast data to 255 bytes\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RtA8VoNLkt7",
        "colab_type": "code",
        "outputId": "69cd64cd-5a6c-4edf-9d67-87f9ff74beba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# printing Training Data from 0-10 indexs\n",
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC_5pEdfL4zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert 1-Dimensional class array to 10-Dimensional matrix using keras np_utils.\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5ydh0qtMvnu",
        "colab_type": "code",
        "outputId": "da7ded99-1bfd-48e8-90f6-1656af62860e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "# After matrix conversion we gets below array\n",
        "Y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WUSNj_POV3q",
        "colab_type": "code",
        "outputId": "7d0633cd-eb50-4329-98cb-eb09c834d215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        }
      },
      "source": [
        "# loading packages for convolution layers  \n",
        "from keras.layers import Activation, MaxPooling2D\n",
        "\n",
        "# START BUILDING MODEL\n",
        "# 1. Start as Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 2. adding Input image of size 28*28*of_channel_1 to Model\n",
        "# Kernal Size of 3*3*1 of no. 32 with activation function \"relu\"\n",
        "# RF for 1st layer would be :3\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28, 28 ,1))) \n",
        "\n",
        "# 3. Now Input image for second layer would be (26,26,32) and\n",
        "# Kernal size for 2nd layer is 3*3*32 of count 64\n",
        "# Receptive Field for second layer 5*5 \n",
        "model.add(Convolution2D(64, 3, 3, activation='relu')) # RF : 5\n",
        "\n",
        "# 4. Input image for 3rd layer would be (24,24,64) and\n",
        "# kernal size of 3*3*64 of count 128\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu')) # RF : 7\n",
        "\n",
        "# 5. Input Image to 4th layer(pooling) would be (22,22,128) \n",
        "# now Max pooling will reduce to half the resolution and\n",
        "# 1/4th to features.\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) # RF would be double : 14\n",
        "\n",
        "# 6. Input image to 5th layer after max pooling is (11,11,128)\n",
        "# and kernal size is 3*3*128 of count 256\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu')) # RF : 16\n",
        "\n",
        "# 7. Input image to 6th layer would be (9,9,256) and\n",
        "# kernal size would be 3*3*256 of count 512\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu')) # RF : 18\n",
        "\n",
        "# 8. Input image to 7th layer would be (7,7,512) and\n",
        "# kernal size would be 3*3*512 of count 1024\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu')) # RF : 20\n",
        "\n",
        "# 9. Input image to 8th layer would be (5,5,1024) and\n",
        "# kernal size would be 3*3*1024 of count 2048\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu')) # RF : 22\n",
        "\n",
        "# 10. Input image to 9th layer would be (3,3,2048) and\n",
        "# kernal size would be 3*3*2048 of count 10\n",
        "model.add(Convolution2D(10, 3, 3)) # RF :24\n",
        "\n",
        "# 11. Input image to Flatten layer would be (1,1,10) and\n",
        "# Flatten layer bring down all multi-layer image to single plane.\n",
        "model.add(Flatten())\n",
        "\n",
        "# 12. Activation Function is to smoothing the output classes\n",
        "# Classifier at last to predict output from model\n",
        "# to normalize the output with continuos distribution\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          184330    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,348,362\n",
            "Trainable params: 25,348,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCfcnFNASd9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Function, Optimizer, \n",
        "# Loss Function to calculate deflection/Difference btw actual value and predicted value\n",
        "# For Accurate prediction we need to minimize error which is work of backpropogation\n",
        "# the proccess to minimize error using updating weights and bias by function called \"optimizer\"\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5u1TRH7QlLP",
        "colab_type": "code",
        "outputId": "4003b93b-afa9-4d83-e3e4-f20458436110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "# to fit model btw X_train and predicted y_train)\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 123s 2ms/step - loss: 0.1410 - acc: 0.9569\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0536 - acc: 0.9845\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0424 - acc: 0.9879\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0337 - acc: 0.9907\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0279 - acc: 0.9922\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0261 - acc: 0.9930\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0220 - acc: 0.9938\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0221 - acc: 0.9940\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0197 - acc: 0.9946\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0164 - acc: 0.9955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d1cbaa8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ItcFufgTany",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model to evaluate the score on the basis of actual output and predicted output. \n",
        "# it will evaluate loss and Accuracy\n",
        "score= model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN0nR5cbTlMh",
        "colab_type": "code",
        "outputId": "72f0f299-ae8b-4d8a-8de5-fb40db0b4e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(score)\n",
        "# model[loss, Accurarcy]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.044243992109429746, 0.9897]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hINiNvFvTv5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model predicting Y_pred from X_test data\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV-CPWp3UCpf",
        "colab_type": "code",
        "outputId": "b6743ce5-d503-4303-84a8-bb4d025d8435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.38629778e-14 1.07974723e-11 1.48652785e-10 2.11398010e-09\n",
            "  7.50692078e-11 1.31784544e-13 1.39210527e-17 1.00000000e+00\n",
            "  1.33193164e-12 5.76125370e-09]\n",
            " [6.95003609e-16 2.08009574e-08 1.00000000e+00 1.60981471e-13\n",
            "  1.05061589e-13 9.49493097e-17 2.96263541e-10 8.57369124e-12\n",
            "  5.10509794e-11 2.55780948e-16]\n",
            " [2.43471493e-11 9.99999881e-01 1.37271972e-10 4.23836716e-10\n",
            "  3.65660497e-08 3.94103878e-08 2.46604247e-11 3.15833937e-09\n",
            "  5.75306114e-09 7.85309595e-10]\n",
            " [9.99999642e-01 1.98506621e-17 2.36462186e-15 1.58766813e-08\n",
            "  3.54817629e-14 2.35165665e-10 3.13387091e-07 5.60532388e-14\n",
            "  5.72681919e-12 1.29710079e-11]\n",
            " [3.28086142e-16 4.91241128e-14 1.58891095e-19 1.94378175e-21\n",
            "  1.00000000e+00 1.87217795e-14 2.30650057e-15 1.33048031e-18\n",
            "  3.06081841e-16 1.60957425e-18]\n",
            " [3.59513987e-15 1.00000000e+00 9.74059598e-15 4.00119433e-15\n",
            "  8.98666419e-11 3.38671067e-13 1.80167550e-14 6.87698108e-13\n",
            "  6.34318281e-13 4.10017564e-15]\n",
            " [1.09176343e-17 2.71338081e-08 4.06622381e-13 1.35525797e-14\n",
            "  1.00000000e+00 1.22547705e-09 2.97739805e-10 3.92079391e-09\n",
            "  1.73310166e-09 7.94287483e-11]\n",
            " [7.14643243e-13 2.98401952e-16 2.28907657e-11 1.17810561e-09\n",
            "  6.20592232e-07 8.11791267e-07 4.62761416e-16 1.06785865e-11\n",
            "  1.20345218e-08 9.99998569e-01]\n",
            " [4.57989549e-12 3.40433468e-15 1.17869937e-14 1.38193368e-08\n",
            "  2.53856452e-14 8.70478392e-01 2.37546768e-02 1.95730319e-15\n",
            "  1.05766878e-01 7.05647224e-14]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ovcK_oeDujR",
        "colab_type": "text"
      },
      "source": [
        "### EXPLAINATION : \n",
        ">***Q. What went wrong ???***\n",
        "> As we know image feature distributed/consists of \n",
        "\n",
        ">**edges, gradients --> texture --> pattern --> parts of object --> object --> scene**\n",
        "\n",
        ">1. In these model after getting features in initial convolution layer, still increases depth of model(channels)\n",
        "2. Input image in dataset is simple which doesn't have much comples features maps.\n",
        "3. Channels will help to get feature but once getting features we need to maintain parameter too.\n",
        "4. We can still be use 32 channels as input and make it constant to acheive output in multiple layers.\n",
        "5. and max pooling also help to get important features early and decrease layer counts.\n",
        "6. This model exceed the RF as we know image should be equal to size of object, which is achieved in initial stage of convolution layers, but still added channels and layers in above models.\n",
        "7. In this model Validation accuracy was worst after 10 epochs it was still 49% , it seems if you run 100 epochs too it will overffit and won't gain any addition to accuracy.\n",
        "8. Loss is too much in this model as channels depth increases which increase model time to calculate. Model already learn important features in initial convolution layers, no need to increase depth of model.\n"
      ]
    }
  ]
}