{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-7B.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-UbhtaBAytM",
        "colab_type": "text"
      },
      "source": [
        "#ENAS Discovered Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHnlX4DnDHDd",
        "colab_type": "text"
      },
      "source": [
        "##Importing All required weapon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pROKc2x9sWB",
        "colab_type": "code",
        "outputId": "fb69b72f-eac3-4f26-b71a-76f5c14038c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras import backend as k\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "% matplotlib inline\n",
        "np.random.seed(2017)\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Activation, Flatten, Dense, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQspSbQTA0ZG",
        "colab_type": "text"
      },
      "source": [
        "##Loading CIFAR-10 Dataset into Train and Test features, labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28TUXnItA0sl",
        "colab_type": "code",
        "outputId": "045cdb43-d010-4d4a-c90f-11edcc8b673d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
        "num_train, img_channels, img_rows, img_cols = train_features.shape\n",
        "num_test, img_channels, img_rows, img_cols = test_features.shape\n",
        "num_classes = len(np.unique(train_labels))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-31hHhUeB07l",
        "colab_type": "text"
      },
      "source": [
        "##Visualizing Datasets values with divided into 10 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42-CSl1EB1TZ",
        "colab_type": "code",
        "outputId": "042c53e2-5c4b-4781-c022-a36f90101979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "class_names = ['airplane', 'automobile','bird','cat', 'deer',\n",
        "              'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "fig = plt.figure(figsize=(8,3))\n",
        "for i in range(num_classes):\n",
        "  ax = fig.add_subplot(2, 5, 1 + i, xticks =[], yticks=[])\n",
        "  idx = np.where(train_labels[:]==i)[0]\n",
        "  feature_idx = train_features[idx,::]\n",
        "  img_num = np.random.randint(feature_idx.shape[0])\n",
        "  im = feature_idx[img_num]\n",
        "  ax.set_title(class_names[i])\n",
        "  plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdAAAADECAYAAAAvbXA5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUAMDAwMDg3PA/IAaGBgYGBicA/8XX+JaT2U4UocAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x216 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO9VezbJEMsH",
        "colab_type": "text"
      },
      "source": [
        "##Reusable method for create Model  Plot with consist of Accuracy, Epoch, Loss of Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILNOBgeHENDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXqo5gICESQp",
        "colab_type": "text"
      },
      "source": [
        "##Reusable function for Accuracy prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbyzsfufESlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(test_x, test_y, model):\n",
        "    result = model.predict(test_x)\n",
        "    predicted_class = np.argmax(result, axis=1)\n",
        "    true_class = np.argmax(test_y, axis=1)\n",
        "    num_correct = np.sum(predicted_class == true_class) \n",
        "    accuracy = float(num_correct)/result.shape[0]\n",
        "    return (accuracy * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dM_sEo4Ea_o",
        "colab_type": "text"
      },
      "source": [
        "##Pre-proccessing of Test and Train features of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJH2yaSeEbTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = train_features.astype('float32')/255\n",
        "test_features = test_features.astype('float32')/255\n",
        "\n",
        "#convert class labels to binary class labels\n",
        "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = np_utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr2DT_6pEmJT",
        "colab_type": "text"
      },
      "source": [
        "##Import Tensorflow package for resizing of layers with moderate space_to_depth changes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smhbgdtC8aag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "# x is input layer \n",
        "#Space_to_depth works as divide block to four equal size and concate in sequential order back to back\n",
        "#Example: 32x32x32 to convert space to depth be like  16x16x128\n",
        "def space_to_depth_x2(x):\n",
        "  return tf.space_to_depth(x, block_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuRKzuxVoCfy",
        "colab_type": "text"
      },
      "source": [
        "## ENAS (Efficient Neural Architecture Search) Architecture: Image Classification\n",
        "![alt text](https://github.com/Mayank01/EVA/blob/master/Session7/Assignment/ENAS_ntw7B.png?raw=true)\n",
        "\n",
        "                                                               "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSBSiErUzMlH",
        "colab_type": "text"
      },
      "source": [
        "##Model Connections:\n",
        "![link text](https://github.com/Mayank01/EVA/blob/master/Session7/Assignment/ENAS_7B.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUJpChe_FIOc",
        "colab_type": "text"
      },
      "source": [
        "##Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3uBT5r-FIpG",
        "colab_type": "code",
        "outputId": "3e281086-86f8-4cc6-c4f4-519685f19ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from keras.layers import Lambda, concatenate, Conv2D, Convolution2D, Input, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "\n",
        "#Define the Model\n",
        "Input_Shape = Input(shape=(32, 32, 3))\n",
        "\n",
        "############ Start ## Division-A #################\n",
        "### Layer-1\n",
        "#Depthwise Separable Convolution : Depth-wise convolution followed by point-wise\n",
        "layer1 = SeparableConv2D(32, 5, padding='same', name='SepConv_01')(Input_Shape)   #Input size 32x32\n",
        "layer1 = BatchNormalization(name='BN_01')(layer1)\n",
        "layer1 = Activation('relu', name='relu_01')(layer1)\n",
        "\n",
        "#Skip Connection Layer-1\n",
        "skip_connect_l1 = layer1              #Input to layer 4,6,8,10,MaxPool-1,MaxPool-2\n",
        "\n",
        "### Layer-2\n",
        "#Normal Convolution\n",
        "layer2 = Conv2D(32, (5, 5), padding='same', name='Conv_02')(layer1)              #Input size 32x32\n",
        "layer2 = BatchNormalization(name='BN_02')(layer2)\n",
        "layer2 = Activation('relu', name='relu_02')(layer2)\n",
        "\n",
        "#Skip Connection Layer-2\n",
        "skip_connect_l2 = layer2              #Input to layer 10,11\n",
        "\n",
        "### Layer-3\n",
        "#Normal Convolution\n",
        "layer3 = Conv2D(32, (5, 5), padding='same', name='Conv_03')(layer2)              #Input size 32x32\n",
        "layer3 = BatchNormalization(name='BN_03')(layer3)\n",
        "layer3 = Activation('relu', name='relu_03')(layer3)\n",
        "\n",
        "#Skip Connection Layer-3\n",
        "skip_connect_l3 = layer3              #Input to layer 7,8,11,12\n",
        "\n",
        "#Add Skip Layer-1 to Layer-4 \n",
        "#Concatation of Layers (1, Layer-3) for Layer-4\n",
        "layer3 = concatenate ([layer3, skip_connect_l1], axis=-1)\n",
        "\n",
        "### Layer-4\n",
        "#Depthwise Separable Convolution : Depth-wise convolution followed by point-wise\n",
        "layer4 = SeparableConv2D(32, 5, padding='same', name='SepConv_04')(layer3)       #Input size 32x32\n",
        "layer4 = BatchNormalization(name='BN_04')(layer4)\n",
        "layer4 = Activation('relu', name='relu_04')(layer4)\n",
        "\n",
        "#Skip Connection Layer-4\n",
        "skip_connect_l4 = layer4              #Input to layer 6,7,8,10,12,MP2,Softmax\n",
        "\n",
        "#Add Skip Layer-1 to Maxpool-1 \n",
        "layer4 = concatenate ([layer4, skip_connect_l1],axis=-1)\n",
        "\n",
        "#MaxPooling Layer-1\n",
        "maxpoolLayer1 = MaxPooling2D(pool_size=(2,2))(layer4)\n",
        "maxpoolLayer1 = Lambda(space_to_depth_x2)(maxpoolLayer1)\n",
        "\n",
        "maxpoolLayer1 = Conv2D(32, (1, 1), padding='same', name='maxpoolLayer1')(layer4)\n",
        "############ End ## Division-A #################\n",
        "\n",
        "############ Start ## Division-B #################\n",
        "### Layer-5\n",
        "#Depthwise Separable Convolution : Depth-wise convolution followed by point-wise\n",
        "layer5 = SeparableConv2D(32, 3, padding='same', name='SepConv_05')(maxpoolLayer1)    #Input size 16x16\n",
        "layer5 = BatchNormalization(name='BN_05')(layer5)\n",
        "layer5 = Activation('relu', name='relu_05')(layer5)\n",
        "\n",
        "layer5 = Lambda(space_to_depth_x2)(layer5)\n",
        "layer5 = Conv2D(32, (1, 1), padding='same', name='layer5')(layer5)\n",
        "\n",
        "#Skip Connection Layer-5\n",
        "skip_connect_l5 = layer5               #Input to layer 7,8,11,12,MP2\n",
        "\n",
        "#Add Skip Layer-1 to Layer-6 \n",
        "skip_con1To6 = Lambda(space_to_depth_x2)(skip_connect_l1)\n",
        "#Add Skip Layer-4 to Layer-6 \n",
        "skip_con4To6 = Lambda(space_to_depth_x2)(skip_connect_l4)\n",
        "\n",
        "#Concatation of Layers (1, 4 and Layer-5) for Layer-6\n",
        "layer5 = concatenate ([layer5, skip_con1To6, skip_con4To6], axis=-1)\n",
        "\n",
        "\n",
        "### Layer-6\n",
        "#Normal Convolution\n",
        "layer6 = Conv2D(32, (5, 5), padding='same', name='Conv_06')(layer5)                 #Input size 16x16\n",
        "layer6 = BatchNormalization(name='BN_06')(layer6)\n",
        "layer6 = Activation('relu', name='relu_06')(layer6)\n",
        "\n",
        "#Skip Connection Layer-6\n",
        "skip_connect_l6 = layer6                #Input to layer 8,9\n",
        "\n",
        "# add Skip Layer 3 to 7 \n",
        "skip_con3To7 = Lambda(space_to_depth_x2)(skip_connect_l3)\n",
        "skip_con3To7 = Conv2D(32, (1, 1), padding='same', name='skip_con3To7_1x1')(skip_con3To7)\n",
        "# add Skip Layer 4 to 7 \n",
        "skip_con4To7 = Lambda(space_to_depth_x2)(skip_connect_l4)\n",
        "skip_con4To7 = Conv2D(32, (1, 1), padding='same', name='skip_con4To7_1x1')(skip_con4To7)\n",
        "# add Skip Layer 5 to 7 \n",
        "skip_con5To7 = skip_connect_l5\n",
        "skip_con5To7 = Conv2D(32, (1, 1), padding='same', name='skip_con5To7_1x1')(skip_con5To7)\n",
        "\n",
        "#Concatation of Layers (3, 4, 5, and Layer-6) for Layer-7\n",
        "layer6 = concatenate ([layer6, skip_con3To7, skip_con4To7, skip_con5To7], axis=-1)\n",
        "layer6 = Conv2D(32, (1, 1), padding='same', name='layer6_1x1')(layer6)\n",
        "### Layer-7\n",
        "#Depthwise Separable Convolution : Depth-wise convolution followed by point-wise\n",
        "layer7 = SeparableConv2D(32, 3, padding='same', name='SepConv_07')(layer6)         #Input size 16x16\n",
        "layer7 = BatchNormalization(name='BN_07')(layer7)\n",
        "layer7 = Activation('relu', name='relu_07')(layer7)\n",
        "\n",
        "#Skip Connection Layer-7\n",
        "skip_connect_l7 = layer7                #Input to layer 10,12,MP2,Softmax\n",
        "\n",
        "#Concatation of Layers (1, 3, 4, 5, 6 and Layer 7) for Layer-8\n",
        "layer7 = concatenate ([layer7, skip_con1To6, skip_con3To7, skip_con4To7, skip_connect_l5, skip_connect_l6])\n",
        "\n",
        "### Layer-8\n",
        "#Depthwise Separable Convolution : Depth-wise convolution followed by point-wise\n",
        "layer8 = SeparableConv2D(32, 5, padding='same', name='SepConv_08')(layer7)         #Input Image 16x16\n",
        "layer8 = BatchNormalization(name='BN_08')(layer8)\n",
        "layer8 = Activation('relu', name='relu_08')(layer8)\n",
        "\n",
        "# add Skip Layer 1 to MaxP -2 \n",
        "skip_con1ToMP2 = Lambda(space_to_depth_x2)(skip_connect_l1)\n",
        "skip_con1ToMP2 = Conv2D(32, (1, 1), padding='same', name='skip_con1ToMP2_1x1')(skip_con1ToMP2)\n",
        "# add Skip Layer 4 to MP2 \n",
        "skip_con4ToMP2 = Lambda(space_to_depth_x2)(skip_connect_l4)\n",
        "skip_con4ToMP2 = Conv2D(32, (1, 1), padding='same', name='skip_con4ToMP2_1x1')(skip_con4ToMP2)\n",
        "# add Skip Layer 5 to MP2 \n",
        "skip_con5ToMP2 = (skip_connect_l5)\n",
        "skip_con5ToMP2 = Conv2D(32, (1, 1), padding='same', name='skip_con5ToMP2_1x1')(skip_con5ToMP2)\n",
        "\n",
        "# add Skip Layer 7 to MP2 \n",
        "skip_con7ToMP2 = (skip_connect_l7)\n",
        "\n",
        "#Concatation of Layers (1, 4 , 5 ,7 and Layer 8) for MaxPool-2\n",
        "layer8 = concatenate ([layer8, skip_con1ToMP2, skip_con4ToMP2, skip_con5ToMP2, skip_con7ToMP2])  #Size 16x16x32\n",
        "layer8 = Conv2D(128, (1, 1), padding='same', name='layer8_1x1')(layer8)\n",
        "\n",
        "#MaxPooling Layer-2\n",
        "maxpoolLayer2 = MaxPooling2D(pool_size=(2,2))(layer8)\n",
        "                         \n",
        "#Add Skip Layer-6 to Layer-9 \n",
        "skip_con6To9 = Lambda(space_to_depth_x2)(skip_connect_l6)\n",
        "\n",
        "#Concatenation of (Maxpool2 + Layer 6)\n",
        "maxpoolLayer2 = concatenate ([maxpoolLayer2, skip_con6To9])       # size 8x8x128\n",
        "\n",
        "############ End ## Division-B #################\n",
        "\n",
        "############ Start ## Division-C #################\n",
        "\n",
        "### Layer-9\n",
        "#Normal Convolution\n",
        "layer9 = Conv2D(32, (5, 5), padding='same', name='Conv_09')(maxpoolLayer2)   #Input 8x8\n",
        "layer9 = BatchNormalization(name='BN_09')(layer9)\n",
        "layer9 = Activation('relu', name='relu_09')(layer9)\n",
        "\n",
        "#Skip Connection Layer-9\n",
        "skip_connect_l9 = layer9                 #Input to layer 10,11\n",
        "\n",
        "# add Skip Layer 1 to 10 \n",
        "skip_con1To10 = Lambda(space_to_depth_x2)(skip_connect_l1)\n",
        "skip_con1To10 = Lambda(space_to_depth_x2)(skip_con1To10)\n",
        "skip_con1To10 = Conv2D(32, (1, 1), padding='same', name='skip_con1To10_1x1')(skip_con1To10)\n",
        "\n",
        "# add Skip Layer 2 to 10\n",
        "skip_con2To10 = Lambda(space_to_depth_x2)(skip_connect_l2)\n",
        "skip_con2To10 = Lambda(space_to_depth_x2)(skip_con2To10)\n",
        "skip_con2To10 = Conv2D(32, (1, 1), padding='same', name='skip_con2To10_1x1')(skip_con2To10)\n",
        "\n",
        "# add Skip Layer 4 to 10 \n",
        "skip_con4To10 = Lambda(space_to_depth_x2)(skip_connect_l4)\n",
        "skip_con4To10 = Lambda(space_to_depth_x2)(skip_con4To10)\n",
        "skip_con4To10 = Conv2D(32, (1, 1), padding='same', name='skip_con4To10_1x1')(skip_con4To10)\n",
        "\n",
        "# add Skip Layer 7 to 10 \n",
        "skip_con7To10 = Lambda(space_to_depth_x2)(skip_connect_l5)\n",
        "\n",
        "#skip_con5ToMP2 = (skip_connect_l5)\n",
        "skip_con7To10 = Conv2D(32, (1, 1), padding='same', name='skip_con7To10_1x1')(skip_con7To10)\n",
        "\n",
        "#Concatation of Layers (1, 2, 4, 7 and Layer-9) for Layer-10\n",
        "layer9 = concatenate ([layer9, skip_con1To10, skip_con2To10, skip_con4To10, skip_con7To10])   #Size 8x8x32\n",
        "\n",
        "### Layer-10\n",
        "#Depthwise Separable Convolution : Depth-wise convolution followed by point-wise\n",
        "layer10 = SeparableConv2D(32, 5, padding='same', name='SepConv_10')(layer9)  #Input 8x8\n",
        "layer10 = BatchNormalization(name='BN_10')(layer10)\n",
        "layer10 = Activation('relu', name='relu_10')(layer10)\n",
        "\n",
        "#Skip Connection Layer-10\n",
        "skip_connect_l10 = layer10               #Input to layer 12,Softmax\n",
        "\n",
        "# add Skip Layer 2 to 11 \n",
        "skip_con2To11 = Lambda(space_to_depth_x2)(skip_connect_l2)\n",
        "skip_con2To11 = Lambda(space_to_depth_x2)(skip_con2To11)\n",
        "skip_con2To11 = Conv2D(32, (1, 1), padding='same', name='skip_con2To11_1x1')(skip_con2To11)\n",
        "\n",
        "# add Skip Layer 3 to 11 \n",
        "skip_con3To11 = Lambda(space_to_depth_x2)(skip_connect_l3)\n",
        "skip_con3To11 = Lambda(space_to_depth_x2)(skip_con3To11)\n",
        "skip_con3To11 = Conv2D(32, (1, 1), padding='same', name='skip_con3To11_1x1')(skip_con3To11)\n",
        "\n",
        "# add Skip Layer 5 to 11\n",
        "skip_con5To11 = Lambda(space_to_depth_x2)(skip_connect_l5)\n",
        "skip_con5To11 = Conv2D(32, (1, 1), padding='same', name='skip_con5To11_1x1')(skip_con5To11)\n",
        "\n",
        "# add Skip Layer 9 to 11 \n",
        "skip_con9To11 = (skip_connect_l9)\n",
        "#Concatation of Layers (2, 3, 5, 9 and Layer-10) for Layer-11\n",
        "layer10 = concatenate ([layer10, skip_con2To11, skip_con3To11, skip_con5To11, skip_con9To11]) #size 8x8x32\n",
        "\n",
        "### Layer-11\n",
        "#Normal Convolution\n",
        "layer11 = Conv2D(32, (3, 3), padding='same', name='conv_11')(layer10)  #Input 8x8\n",
        "layer11 = BatchNormalization(name='BN_11')(layer11)\n",
        "layer11 = Activation('relu', name='relu_11')(layer11)\n",
        "\n",
        "# add Skip Layer 3 to 12 \n",
        "skip_con3To12 = Lambda(space_to_depth_x2)(skip_connect_l3)\n",
        "skip_con3To12 = Lambda(space_to_depth_x2)(skip_con3To12)\n",
        "skip_con3To12 = Conv2D(32, (1, 1), padding='same', name='skip_con3To12_1x1')(skip_con3To12)\n",
        "\n",
        "# add Skip Layer 4 to 12 \n",
        "skip_con4To12 = Lambda(space_to_depth_x2)(skip_connect_l4)\n",
        "skip_con4To12 = Lambda(space_to_depth_x2)(skip_con4To12)\n",
        "skip_con4To12 = Conv2D(32, (1, 1), padding='same', name='skip_con4To12_1x1')(skip_con4To12)\n",
        "\n",
        "# add Skip Layer 5 to 12 \n",
        "skip_con5To12 = Lambda(space_to_depth_x2)(skip_connect_l5)\n",
        "skip_con5To12 = Conv2D(32, (1, 1), padding='same', name='skip_con5To12_1x1')(skip_con5To12)\n",
        "\n",
        "# add Skip Layer 7 to 12\n",
        "skip_con7To12 = Lambda(space_to_depth_x2)(skip_connect_l7)\n",
        "skip_con7To12 = Conv2D(32, (1, 1), padding='same', name='skip_con7To12_1x1')(skip_con7To12)\n",
        "\n",
        "# add Skip Layer 10 to 12 \n",
        "skip_con9To11 = (skip_connect_l10)\n",
        "\n",
        "#Concatation of Layers (3, 4, 5, 7, 10 and Layer-11) for Layer-12\n",
        "layer11 = concatenate ([layer11, skip_con3To12, skip_con4To12, skip_con5To12, skip_con7To12, skip_connect_l10])\n",
        "\n",
        "### Layer-12\n",
        "#Depthwise Separable Convolution : Depth-wise convolution followed by point-wise\n",
        "layer12 = SeparableConv2D(64, 5, name='Sep_Conv_12')(layer11) #Input 8x8\n",
        "layer12 = BatchNormalization(name='BN_12')(layer12)\n",
        "layer12 = Activation('relu', name='relu_12')(layer12)\n",
        "\n",
        "# add Skip Layer 4 to SoftMax \n",
        "skip_con4ToSM = Lambda(space_to_depth_x2)(skip_connect_l4)\n",
        "skip_con4ToSM = Lambda(space_to_depth_x2)(skip_con4ToSM)\n",
        "skip_con4ToSM = Lambda(space_to_depth_x2)(skip_con4ToSM)\n",
        "skip_con4ToSM = Conv2D(64, (1, 1), padding='same', name='skip_con4ToSM_1x1')(skip_con4ToSM)\n",
        "\n",
        "# add Skip Layer 7 to SoftMax\n",
        "skip_con7ToSM = Lambda(space_to_depth_x2)(skip_connect_l7)\n",
        "skip_con7ToSM = Lambda(space_to_depth_x2)(skip_con7ToSM)\n",
        "skip_con7ToSM = Conv2D(64, (1, 1), padding='same', name='skip_con7ToSM_1x1')(skip_con7ToSM)\n",
        "\n",
        "# add Skip Layer 10 to SoftMax \n",
        "skip_con10ToSM = Lambda(space_to_depth_x2)(skip_connect_l10)\n",
        "skip_con10ToSM = Lambda(space_to_depth_x2)(skip_connect_l10)\n",
        "skip_con10ToSM = Conv2D(64, (1, 1), padding='same', name='skip_con10ToSM_1x1')(skip_con10ToSM)\n",
        "\n",
        "#layer12 = GlobalAveragePooling2D()(layer12)\n",
        "layer12 = concatenate ([layer12, skip_con4ToSM, skip_con7ToSM, skip_con10ToSM])\n",
        "layer12 = (Convolution2D(10, 4, 4))(layer12)\n",
        "\n",
        "layer12 = GlobalAveragePooling2D()(layer12)\n",
        "\n",
        "############ End ## Division-C #################\n",
        "\n",
        "#Flatten Layer\n",
        "#fLayer = Flatten()(layer12)\n",
        "output = Activation('softmax')(layer12)\n",
        "\n",
        "model = Model(inputs = [Input_Shape], output=[output])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:264: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:274: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntSmDl0Qdi3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTOjwvOMFaAe",
        "colab_type": "text"
      },
      "source": [
        "##Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPzD0-2wFafQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81b45ddc-3101-45fb-c28f-5801bb3f86bd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "SepConv_01 (SeparableConv2D)    (None, 32, 32, 32)   203         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "BN_01 (BatchNormalization)      (None, 32, 32, 32)   128         SepConv_01[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "relu_01 (Activation)            (None, 32, 32, 32)   0           BN_01[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv_02 (Conv2D)                (None, 32, 32, 32)   25632       relu_01[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "BN_02 (BatchNormalization)      (None, 32, 32, 32)   128         Conv_02[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "relu_02 (Activation)            (None, 32, 32, 32)   0           BN_02[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv_03 (Conv2D)                (None, 32, 32, 32)   25632       relu_02[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "BN_03 (BatchNormalization)      (None, 32, 32, 32)   128         Conv_03[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "relu_03 (Activation)            (None, 32, 32, 32)   0           BN_03[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 64)   0           relu_03[0][0]                    \n",
            "                                                                 relu_01[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "SepConv_04 (SeparableConv2D)    (None, 32, 32, 32)   3680        concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BN_04 (BatchNormalization)      (None, 32, 32, 32)   128         SepConv_04[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "relu_04 (Activation)            (None, 32, 32, 32)   0           BN_04[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 64)   0           relu_04[0][0]                    \n",
            "                                                                 relu_01[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "maxpoolLayer1 (Conv2D)          (None, 32, 32, 32)   2080        concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "SepConv_05 (SeparableConv2D)    (None, 32, 32, 32)   1344        maxpoolLayer1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "BN_05 (BatchNormalization)      (None, 32, 32, 32)   128         SepConv_05[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "relu_05 (Activation)            (None, 32, 32, 32)   0           BN_05[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_36 (Lambda)              (None, 16, 16, 128)  0           relu_05[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer5 (Conv2D)                 (None, 16, 16, 32)   4128        lambda_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_37 (Lambda)              (None, 16, 16, 128)  0           relu_01[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_38 (Lambda)              (None, 16, 16, 128)  0           relu_04[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 16, 16, 288)  0           layer5[0][0]                     \n",
            "                                                                 lambda_37[0][0]                  \n",
            "                                                                 lambda_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Conv_06 (Conv2D)                (None, 16, 16, 32)   230432      concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BN_06 (BatchNormalization)      (None, 16, 16, 32)   128         Conv_06[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_39 (Lambda)              (None, 16, 16, 128)  0           relu_03[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_40 (Lambda)              (None, 16, 16, 128)  0           relu_04[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "relu_06 (Activation)            (None, 16, 16, 32)   0           BN_06[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "skip_con3To7_1x1 (Conv2D)       (None, 16, 16, 32)   4128        lambda_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con4To7_1x1 (Conv2D)       (None, 16, 16, 32)   4128        lambda_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con5To7_1x1 (Conv2D)       (None, 16, 16, 32)   1056        layer5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 16, 16, 128)  0           relu_06[0][0]                    \n",
            "                                                                 skip_con3To7_1x1[0][0]           \n",
            "                                                                 skip_con4To7_1x1[0][0]           \n",
            "                                                                 skip_con5To7_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "layer6_1x1 (Conv2D)             (None, 16, 16, 32)   4128        concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "SepConv_07 (SeparableConv2D)    (None, 16, 16, 32)   1344        layer6_1x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "BN_07 (BatchNormalization)      (None, 16, 16, 32)   128         SepConv_07[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "relu_07 (Activation)            (None, 16, 16, 32)   0           BN_07[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 288)  0           relu_07[0][0]                    \n",
            "                                                                 lambda_37[0][0]                  \n",
            "                                                                 skip_con3To7_1x1[0][0]           \n",
            "                                                                 skip_con4To7_1x1[0][0]           \n",
            "                                                                 layer5[0][0]                     \n",
            "                                                                 relu_06[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "SepConv_08 (SeparableConv2D)    (None, 16, 16, 32)   16448       concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BN_08 (BatchNormalization)      (None, 16, 16, 32)   128         SepConv_08[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_41 (Lambda)              (None, 16, 16, 128)  0           relu_01[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_42 (Lambda)              (None, 16, 16, 128)  0           relu_04[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "relu_08 (Activation)            (None, 16, 16, 32)   0           BN_08[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "skip_con1ToMP2_1x1 (Conv2D)     (None, 16, 16, 32)   4128        lambda_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con4ToMP2_1x1 (Conv2D)     (None, 16, 16, 32)   4128        lambda_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con5ToMP2_1x1 (Conv2D)     (None, 16, 16, 32)   1056        layer5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 160)  0           relu_08[0][0]                    \n",
            "                                                                 skip_con1ToMP2_1x1[0][0]         \n",
            "                                                                 skip_con4ToMP2_1x1[0][0]         \n",
            "                                                                 skip_con5ToMP2_1x1[0][0]         \n",
            "                                                                 relu_07[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer8_1x1 (Conv2D)             (None, 16, 16, 128)  20608       concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 128)    0           layer8_1x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_43 (Lambda)              (None, 8, 8, 128)    0           relu_06[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 8, 8, 256)    0           max_pooling2d_4[0][0]            \n",
            "                                                                 lambda_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Conv_09 (Conv2D)                (None, 8, 8, 32)     204832      concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_44 (Lambda)              (None, 16, 16, 128)  0           relu_01[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_46 (Lambda)              (None, 16, 16, 128)  0           relu_02[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_48 (Lambda)              (None, 16, 16, 128)  0           relu_04[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "BN_09 (BatchNormalization)      (None, 8, 8, 32)     128         Conv_09[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_45 (Lambda)              (None, 8, 8, 512)    0           lambda_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_47 (Lambda)              (None, 8, 8, 512)    0           lambda_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_49 (Lambda)              (None, 8, 8, 512)    0           lambda_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_50 (Lambda)              (None, 8, 8, 128)    0           layer5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu_09 (Activation)            (None, 8, 8, 32)     0           BN_09[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "skip_con1To10_1x1 (Conv2D)      (None, 8, 8, 32)     16416       lambda_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con2To10_1x1 (Conv2D)      (None, 8, 8, 32)     16416       lambda_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con4To10_1x1 (Conv2D)      (None, 8, 8, 32)     16416       lambda_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con7To10_1x1 (Conv2D)      (None, 8, 8, 32)     4128        lambda_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 8, 8, 160)    0           relu_09[0][0]                    \n",
            "                                                                 skip_con1To10_1x1[0][0]          \n",
            "                                                                 skip_con2To10_1x1[0][0]          \n",
            "                                                                 skip_con4To10_1x1[0][0]          \n",
            "                                                                 skip_con7To10_1x1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "SepConv_10 (SeparableConv2D)    (None, 8, 8, 32)     9152        concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_51 (Lambda)              (None, 16, 16, 128)  0           relu_02[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_53 (Lambda)              (None, 16, 16, 128)  0           relu_03[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "BN_10 (BatchNormalization)      (None, 8, 8, 32)     128         SepConv_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_52 (Lambda)              (None, 8, 8, 512)    0           lambda_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_54 (Lambda)              (None, 8, 8, 512)    0           lambda_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_55 (Lambda)              (None, 8, 8, 128)    0           layer5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu_10 (Activation)            (None, 8, 8, 32)     0           BN_10[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "skip_con2To11_1x1 (Conv2D)      (None, 8, 8, 32)     16416       lambda_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con3To11_1x1 (Conv2D)      (None, 8, 8, 32)     16416       lambda_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con5To11_1x1 (Conv2D)      (None, 8, 8, 32)     4128        lambda_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 8, 8, 160)    0           relu_10[0][0]                    \n",
            "                                                                 skip_con2To11_1x1[0][0]          \n",
            "                                                                 skip_con3To11_1x1[0][0]          \n",
            "                                                                 skip_con5To11_1x1[0][0]          \n",
            "                                                                 relu_09[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_11 (Conv2D)                (None, 8, 8, 32)     46112       concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_56 (Lambda)              (None, 16, 16, 128)  0           relu_03[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_58 (Lambda)              (None, 16, 16, 128)  0           relu_04[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "BN_11 (BatchNormalization)      (None, 8, 8, 32)     128         conv_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_57 (Lambda)              (None, 8, 8, 512)    0           lambda_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_59 (Lambda)              (None, 8, 8, 512)    0           lambda_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_60 (Lambda)              (None, 8, 8, 128)    0           layer5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_61 (Lambda)              (None, 8, 8, 128)    0           relu_07[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "relu_11 (Activation)            (None, 8, 8, 32)     0           BN_11[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "skip_con3To12_1x1 (Conv2D)      (None, 8, 8, 32)     16416       lambda_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con4To12_1x1 (Conv2D)      (None, 8, 8, 32)     16416       lambda_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con5To12_1x1 (Conv2D)      (None, 8, 8, 32)     4128        lambda_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con7To12_1x1 (Conv2D)      (None, 8, 8, 32)     4128        lambda_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 8, 8, 192)    0           relu_11[0][0]                    \n",
            "                                                                 skip_con3To12_1x1[0][0]          \n",
            "                                                                 skip_con4To12_1x1[0][0]          \n",
            "                                                                 skip_con5To12_1x1[0][0]          \n",
            "                                                                 skip_con7To12_1x1[0][0]          \n",
            "                                                                 relu_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_62 (Lambda)              (None, 16, 16, 128)  0           relu_04[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Sep_Conv_12 (SeparableConv2D)   (None, 4, 4, 64)     17152       concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_63 (Lambda)              (None, 8, 8, 512)    0           lambda_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_65 (Lambda)              (None, 8, 8, 128)    0           relu_07[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "BN_12 (BatchNormalization)      (None, 4, 4, 64)     256         Sep_Conv_12[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_64 (Lambda)              (None, 4, 4, 2048)   0           lambda_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_66 (Lambda)              (None, 4, 4, 512)    0           lambda_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_68 (Lambda)              (None, 4, 4, 128)    0           relu_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "relu_12 (Activation)            (None, 4, 4, 64)     0           BN_12[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "skip_con4ToSM_1x1 (Conv2D)      (None, 4, 4, 64)     131136      lambda_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con7ToSM_1x1 (Conv2D)      (None, 4, 4, 64)     32832       lambda_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "skip_con10ToSM_1x1 (Conv2D)     (None, 4, 4, 64)     8256        lambda_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 4, 4, 256)    0           relu_12[0][0]                    \n",
            "                                                                 skip_con4ToSM_1x1[0][0]          \n",
            "                                                                 skip_con7ToSM_1x1[0][0]          \n",
            "                                                                 skip_con10ToSM_1x1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 1, 1, 10)     40970       concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 10)           0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 10)           0           global_average_pooling2d_2[0][0] \n",
            "==================================================================================================\n",
            "Total params: 977,813\n",
            "Trainable params: 976,981\n",
            "Non-trainable params: 832\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf4u8CPDFazs",
        "colab_type": "text"
      },
      "source": [
        "##Network Compilation and LearningRate scheduler with model comparison Test & Train Plot "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dLWgyC5FbKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f06acc3-2244-4b24-b3a3-ab3c1feefc29"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.optimizers import Adam\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "datagen = ImageDataGenerator(zoom_range = 0.0, horizontal_flip = False)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "#train model \n",
        "start = time.time()\n",
        "\n",
        "model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 128),\n",
        "                                samples_per_epoch = train_features.shape[0], nb_epoch = 100,\n",
        "                                callbacks=[LearningRateScheduler(scheduler, verbose=1)],\n",
        "                                validation_data = (test_features, test_labels), verbose = 1)\n",
        "end = time.time()\n",
        "print(\"Model took %0.2f second to train\"%(end-start))\n",
        "\n",
        "#Plot Model History\n",
        "plot_model_history(model_info)\n",
        "\n",
        "#compute test accuracy \n",
        "print(\"Accuracy on test DATA  is : %0.2f\" %accuracy(test_features, test_labels, model))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=100)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "390/390 [==============================] - 42s 108ms/step - loss: 0.6263 - acc: 0.8161 - val_loss: 2.8037 - val_acc: 0.3927\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.2380 - acc: 0.9171 - val_loss: 1.7477 - val_acc: 0.6443\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.0998 - acc: 0.9648 - val_loss: 1.5309 - val_acc: 0.6912\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.0501 - acc: 0.9841 - val_loss: 1.6720 - val_acc: 0.6742\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.0186 - acc: 0.9951 - val_loss: 1.3451 - val_acc: 0.7317\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.0062 - acc: 0.9990 - val_loss: 1.2905 - val_acc: 0.7565\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.2540 - val_acc: 0.7692\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 7.3916e-04 - acc: 1.0000 - val_loss: 1.2578 - val_acc: 0.7714\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 5.1545e-04 - acc: 1.0000 - val_loss: 1.2638 - val_acc: 0.7715\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 4.0162e-04 - acc: 1.0000 - val_loss: 1.2769 - val_acc: 0.7735\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.3370e-04 - acc: 1.0000 - val_loss: 1.2857 - val_acc: 0.7745\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.8623e-04 - acc: 1.0000 - val_loss: 1.2906 - val_acc: 0.7731\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.4564e-04 - acc: 1.0000 - val_loss: 1.3011 - val_acc: 0.7747\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.0880e-04 - acc: 1.0000 - val_loss: 1.3098 - val_acc: 0.7753\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.8242e-04 - acc: 1.0000 - val_loss: 1.3185 - val_acc: 0.7741\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.5551e-04 - acc: 1.0000 - val_loss: 1.3312 - val_acc: 0.7756\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.3798e-04 - acc: 1.0000 - val_loss: 1.3388 - val_acc: 0.7754\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.1590e-04 - acc: 1.0000 - val_loss: 1.3479 - val_acc: 0.7769\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.0582e-04 - acc: 1.0000 - val_loss: 1.3568 - val_acc: 0.7758\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 8.9550e-05 - acc: 1.0000 - val_loss: 1.3692 - val_acc: 0.7754\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 7.8052e-05 - acc: 1.0000 - val_loss: 1.3752 - val_acc: 0.7761\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 6.6386e-05 - acc: 1.0000 - val_loss: 1.3874 - val_acc: 0.7771\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 6.0856e-05 - acc: 1.0000 - val_loss: 1.3995 - val_acc: 0.7763\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 5.0134e-05 - acc: 1.0000 - val_loss: 1.4111 - val_acc: 0.7759\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 4.3673e-05 - acc: 1.0000 - val_loss: 1.4206 - val_acc: 0.7760\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.7488e-05 - acc: 1.0000 - val_loss: 1.4285 - val_acc: 0.7768\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.2427e-05 - acc: 1.0000 - val_loss: 1.4390 - val_acc: 0.7769\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.7869e-05 - acc: 1.0000 - val_loss: 1.4522 - val_acc: 0.7776\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.3309e-05 - acc: 1.0000 - val_loss: 1.4635 - val_acc: 0.7766\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.0562e-05 - acc: 1.0000 - val_loss: 1.4778 - val_acc: 0.7769\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.7075e-05 - acc: 1.0000 - val_loss: 1.4847 - val_acc: 0.7784\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.4632e-05 - acc: 1.0000 - val_loss: 1.4948 - val_acc: 0.7773\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.2371e-05 - acc: 1.0000 - val_loss: 1.5116 - val_acc: 0.7782\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.0172e-05 - acc: 1.0000 - val_loss: 1.5224 - val_acc: 0.7779\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 9.4079e-06 - acc: 1.0000 - val_loss: 1.5375 - val_acc: 0.7776\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 7.6102e-06 - acc: 1.0000 - val_loss: 1.5441 - val_acc: 0.7789\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 6.4114e-06 - acc: 1.0000 - val_loss: 1.5614 - val_acc: 0.7773\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 5.5117e-06 - acc: 1.0000 - val_loss: 1.5689 - val_acc: 0.7788\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 4.7698e-06 - acc: 1.0000 - val_loss: 1.5846 - val_acc: 0.7777\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.8219e-06 - acc: 1.0000 - val_loss: 1.5987 - val_acc: 0.7783\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.1863e-06 - acc: 1.0000 - val_loss: 1.6104 - val_acc: 0.7787\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.7425e-06 - acc: 1.0000 - val_loss: 1.6229 - val_acc: 0.7789\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.3525e-06 - acc: 1.0000 - val_loss: 1.6339 - val_acc: 0.7799\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.2642e-06 - acc: 1.0000 - val_loss: 1.6456 - val_acc: 0.7789\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.7204e-06 - acc: 1.0000 - val_loss: 1.6578 - val_acc: 0.7784\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 1.5733e-06 - acc: 1.0000 - val_loss: 1.6671 - val_acc: 0.7789\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.2279e-06 - acc: 1.0000 - val_loss: 1.6788 - val_acc: 0.7789\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.1129e-06 - acc: 1.0000 - val_loss: 1.7002 - val_acc: 0.7784\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 9.5399e-07 - acc: 1.0000 - val_loss: 1.7035 - val_acc: 0.7805\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.0069 - acc: 0.9981 - val_loss: 1.9176 - val_acc: 0.7527\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0001769912.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 1.8478 - val_acc: 0.7584\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0001737217.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.3620e-04 - acc: 1.0000 - val_loss: 1.7897 - val_acc: 0.7663\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0001705708.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 5.7893e-05 - acc: 1.0000 - val_loss: 1.7800 - val_acc: 0.7682\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0001675322.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.9364e-05 - acc: 1.0000 - val_loss: 1.7782 - val_acc: 0.7682\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0001646.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.3434e-05 - acc: 1.0000 - val_loss: 1.7735 - val_acc: 0.7693\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0001617687.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.7628e-05 - acc: 1.0000 - val_loss: 1.7717 - val_acc: 0.7701\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0001590331.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.4069e-05 - acc: 1.0000 - val_loss: 1.7698 - val_acc: 0.7705\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0001563885.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.1061e-05 - acc: 1.0000 - val_loss: 1.7678 - val_acc: 0.7702\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0001538304.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.8626e-05 - acc: 1.0000 - val_loss: 1.7671 - val_acc: 0.7707\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.0001513546.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.6070e-05 - acc: 1.0000 - val_loss: 1.7660 - val_acc: 0.7709\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0001489573.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.9618e-05 - acc: 1.0000 - val_loss: 1.7637 - val_acc: 0.7709\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0001466347.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.3612e-05 - acc: 1.0000 - val_loss: 1.7610 - val_acc: 0.7708\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0001443835.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.1009e-05 - acc: 1.0000 - val_loss: 1.7623 - val_acc: 0.7718\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0001422003.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 9.4794e-06 - acc: 1.0000 - val_loss: 1.7572 - val_acc: 0.7726\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0001400822.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 9.0230e-06 - acc: 1.0000 - val_loss: 1.7584 - val_acc: 0.7715\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0001380262.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 8.2220e-06 - acc: 1.0000 - val_loss: 1.7583 - val_acc: 0.7724\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0001360297.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 6.5919e-06 - acc: 1.0000 - val_loss: 1.7580 - val_acc: 0.7727\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0001340902.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 6.2772e-06 - acc: 1.0000 - val_loss: 1.7597 - val_acc: 0.7729\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0001322052.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 5.5747e-06 - acc: 1.0000 - val_loss: 1.7574 - val_acc: 0.7727\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0001303724.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 5.0048e-06 - acc: 1.0000 - val_loss: 1.7584 - val_acc: 0.7725\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0001285898.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 4.3162e-06 - acc: 1.0000 - val_loss: 1.7589 - val_acc: 0.7728\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0001268553.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.8783e-06 - acc: 1.0000 - val_loss: 1.7600 - val_acc: 0.7730\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0001251669.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.5329e-06 - acc: 1.0000 - val_loss: 1.7594 - val_acc: 0.7730\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0001235229.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.0641e-06 - acc: 1.0000 - val_loss: 1.7645 - val_acc: 0.7728\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0001219215.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.8065e-06 - acc: 1.0000 - val_loss: 1.7627 - val_acc: 0.7749\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0001203611.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.3824e-06 - acc: 1.0000 - val_loss: 1.7624 - val_acc: 0.7743\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0001188401.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.2176e-06 - acc: 1.0000 - val_loss: 1.7651 - val_acc: 0.7747\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0001173571.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.0644e-06 - acc: 1.0000 - val_loss: 1.7675 - val_acc: 0.7758\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0001159107.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.7249e-06 - acc: 1.0000 - val_loss: 1.7710 - val_acc: 0.7744\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.0001144994.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.4623e-06 - acc: 1.0000 - val_loss: 1.7735 - val_acc: 0.7770\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.0001131222.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.3920e-06 - acc: 1.0000 - val_loss: 1.7764 - val_acc: 0.7758\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.0001117776.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.2370e-06 - acc: 1.0000 - val_loss: 1.7767 - val_acc: 0.7755\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.0001104647.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.0958e-06 - acc: 1.0000 - val_loss: 1.7828 - val_acc: 0.7765\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.0001091822.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.0228e-06 - acc: 1.0000 - val_loss: 1.7859 - val_acc: 0.7762\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.0001079292.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 8.8264e-07 - acc: 1.0000 - val_loss: 1.7906 - val_acc: 0.7765\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.0001067046.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 7.8855e-07 - acc: 1.0000 - val_loss: 1.7937 - val_acc: 0.7774\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.0001055075.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 6.8890e-07 - acc: 1.0000 - val_loss: 1.7991 - val_acc: 0.7769\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.0001043369.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 6.5014e-07 - acc: 1.0000 - val_loss: 1.8027 - val_acc: 0.7785\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.0001031921.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 5.7557e-07 - acc: 1.0000 - val_loss: 1.8092 - val_acc: 0.7779\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.0001020721.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 5.1919e-07 - acc: 1.0000 - val_loss: 1.8171 - val_acc: 0.7789\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.0001009761.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 4.7181e-07 - acc: 1.0000 - val_loss: 1.8224 - val_acc: 0.7786\n",
            "Epoch 92/100\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 9.99034e-05.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 4.2364e-07 - acc: 1.0000 - val_loss: 1.8259 - val_acc: 0.7779\n",
            "Epoch 93/100\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 9.88533e-05.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.9945e-07 - acc: 1.0000 - val_loss: 1.8367 - val_acc: 0.7794\n",
            "Epoch 94/100\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 9.7825e-05.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.6017e-07 - acc: 1.0000 - val_loss: 1.8347 - val_acc: 0.7776\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 9.68179e-05.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.5226e-07 - acc: 1.0000 - val_loss: 1.8458 - val_acc: 0.7794\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 9.58313e-05.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.6109e-07 - acc: 1.0000 - val_loss: 1.8545 - val_acc: 0.7770\n",
            "Epoch 97/100\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 9.48647e-05.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 3.0798e-07 - acc: 1.0000 - val_loss: 1.8579 - val_acc: 0.7789\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 9.39173e-05.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.8757e-07 - acc: 1.0000 - val_loss: 1.8589 - val_acc: 0.7786\n",
            "Epoch 99/100\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 9.29887e-05.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.5475e-07 - acc: 1.0000 - val_loss: 1.8671 - val_acc: 0.7781\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 9.20782e-05.\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 2.3119e-07 - acc: 1.0000 - val_loss: 1.8741 - val_acc: 0.7772\n",
            "Model took 3598.67 second to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAFNCAYAAAC5cXZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPTMzMzMzsyrkYs/MzMzMzKwK/T8aROFw5yc4jQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test DATA  is : 77.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pfj_5GBGp8L",
        "colab_type": "text"
      },
      "source": [
        "##Model Score with huge overfitting: need to add Data agumentation/Regularization techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lbbDNRCCewk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb1ed943-9f15-462a-f533-205ca49cee29"
      },
      "source": [
        "score = model.evaluate(test_features, test_labels, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.8741759154319764, 0.7772]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}